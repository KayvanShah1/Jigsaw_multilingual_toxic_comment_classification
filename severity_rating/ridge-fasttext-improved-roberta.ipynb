{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "511f64cd",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-01-06T10:02:06.643773Z",
     "iopub.status.busy": "2022-01-06T10:02:06.637348Z",
     "iopub.status.idle": "2022-01-06T10:02:06.651431Z",
     "shell.execute_reply": "2022-01-06T10:02:06.652007Z"
    },
    "papermill": {
     "duration": 0.032376,
     "end_time": "2022-01-06T10:02:06.652332",
     "exception": false,
     "start_time": "2022-01-06T10:02:06.619956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def is_private(): return len(pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')) != 7537"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004bea24",
   "metadata": {
    "papermill": {
     "duration": 0.01066,
     "end_time": "2022-01-06T10:02:06.674242",
     "exception": false,
     "start_time": "2022-01-06T10:02:06.663582",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Base Ridge Ensemble 🔥\n",
    "_____\n",
    "#### **Credit:** Chryzal [[notebook](https://www.kaggle.com/chryzal/jigsaw-ensemble-0-864)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42ef2c50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T10:02:06.734131Z",
     "iopub.status.busy": "2022-01-06T10:02:06.705266Z",
     "iopub.status.idle": "2022-01-06T10:02:06.880018Z",
     "shell.execute_reply": "2022-01-06T10:02:06.879406Z"
    },
    "papermill": {
     "duration": 0.195157,
     "end_time": "2022-01-06T10:02:06.880176",
     "exception": false,
     "start_time": "2022-01-06T10:02:06.685019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if is_private():\n",
    "    import gc\n",
    "    import nltk\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from scipy import sparse\n",
    "    from pprint import pprint\n",
    "    from nltk.corpus import stopwords\n",
    "    from IPython.display import display\n",
    "    from sklearn.linear_model import Ridge\n",
    "    from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "    from sklearn.base import TransformerMixin, BaseEstimator\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    import warnings; warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    df = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv\")\n",
    "    for col in ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']: display(df.loc[df[col] == 1, ['comment_text', col]].sample(10))\n",
    "\n",
    "    df['severe_toxic'] = df.severe_toxic * 2\n",
    "    df['y'] = (df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis = 1)).astype(int)\n",
    "    df['y'] = df['y'] / df['y'].max()\n",
    "    df = df[['comment_text', 'y']].rename(columns = {'comment_text': 'text'})\n",
    "\n",
    "    n_folds = 7\n",
    "    frac_1 = 0.4\n",
    "    frac_1_factor = 1.5\n",
    "    for fld in range(n_folds):\n",
    "        tmp_df = pd.concat([df[df.y > 0].sample(frac = frac_1, random_state = 10 * (fld + 1)), df[df.y == 0].sample(n = int(len(df[df.y > 0]) * frac_1 * frac_1_factor), random_state = 10 * (fld + 1))], axis = 0).sample(frac = 1, random_state = 10 * (fld + 1))\n",
    "        tmp_df.to_csv(f'/kaggle/working/df_fld{fld}.csv', index = False)\n",
    "\n",
    "    stop = stopwords.words('english')\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "    def lemmatize_text(text): return [lemmatizer.lemmatize(w) for w in text]\n",
    "\n",
    "    def clean(data, col):\n",
    "        data[col] = data[col].str.replace(r\"what's\", \"what is \")\n",
    "        data[col] = data[col].str.replace(r\"\\'ve\", \" have \")\n",
    "        data[col] = data[col].str.replace(r\"can't\", \"cannot \")\n",
    "        data[col] = data[col].str.replace(r\"n't\", \" not \")\n",
    "        data[col] = data[col].str.replace(r\"i'm\", \"i am \")\n",
    "        data[col] = data[col].str.replace(r\"\\'re\", \" are \")\n",
    "        data[col] = data[col].str.replace(r\"\\'d\", \" would \")\n",
    "        data[col] = data[col].str.replace(r\"\\'ll\", \" will \")\n",
    "        data[col] = data[col].str.replace(r\"\\'scuse\", \" excuse \")\n",
    "        data[col] = data[col].str.replace(r\"\\'s\", \" \")\n",
    "        data[col] = data[col].str.replace('\\n', ' \\n ')\n",
    "        data[col] = data[col].str.replace(r'([a-zA-Z]+)([/!?.])([a-zA-Z]+)', r'\\1 \\2 \\3')\n",
    "        data[col] = data[col].str.replace(r'([*!?\\'])\\1\\1{2,}', r'\\1\\1\\1')\n",
    "        data[col] = data[col].str.replace(r'([*!?\\']+)', r' \\1 ')\n",
    "        data[col] = data[col].str.replace(r'([a-zA-Z])\\1{2,}\\b', r'\\1\\1')\n",
    "        data[col] = data[col].str.replace(r'([a-zA-Z])\\1\\1{2,}\\B', r'\\1\\1\\1')\n",
    "        data[col] = data[col].str.replace(r'[ ]{2,}', ' ').str.strip()\n",
    "        data[col] = data[col].str.replace(r'[ ]{2,}', ' ').str.strip()\n",
    "        data[col] = data[col].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "        return data\n",
    "\n",
    "    test_clean_df = pd.DataFrame({\"text\": [\"heyy\\n\\nkkdsfj\", \"hi   how/are/you ???\", \"hey?????\", \"noooo!!!!!!!!!   comeone !! \", \"cooooooooool     brooooooooooo  coool brooo\", \"naaaahhhhhhh\"]})\n",
    "    display(test_clean_df)\n",
    "    clean(test_clean_df, 'text')\n",
    "    df = clean(df, 'text')\n",
    "\n",
    "    n_folds = 7\n",
    "    frac_1 = 0.3\n",
    "    frac_1_factor = 1.2\n",
    "    for fld in range(n_folds):\n",
    "        tmp_df = pd.concat([df[df.y > 0].sample(frac = frac_1, random_state = 10 * (fld + 1)), df[df.y == 0].sample(n = int(len(df[df.y > 0]) * frac_1 * frac_1_factor), random_state = 10 * (fld + 1))], axis = 0).sample(frac = 1, random_state = 10 * (fld + 1))\n",
    "        tmp_df.to_csv(f'/kaggle/working/df_clean_fld{fld}.csv', index = False)\n",
    "    del df, tmp_df\n",
    "    gc.collect()\n",
    "\n",
    "    df_ = pd.read_csv(\"../input/ruddit-jigsaw-dataset/Dataset/ruddit_with_text.csv\")\n",
    "    df_ = df_[['txt', 'offensiveness_score']].rename(columns = {'txt': 'text', 'offensiveness_score': 'y'})\n",
    "    df_['y'] = (df_['y'] - df_.y.min()) / (df_.y.max() - df_.y.min())\n",
    "\n",
    "    n_folds = 7\n",
    "    frac_1 = 0.7\n",
    "    for fld in range(n_folds):\n",
    "        tmp_df = df_.sample(frac = frac_1, random_state = 10 * (fld + 1))\n",
    "        tmp_df.to_csv(f'/kaggle/working/df2_fld{fld}.csv', index = False)\n",
    "    del tmp_df, df_\n",
    "    gc.collect()\n",
    "\n",
    "    df_val = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\n",
    "    df_sub = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\n",
    "\n",
    "    # NOT USED\n",
    "    class LengthTransformer(BaseEstimator, TransformerMixin):\n",
    "        def fit(self, X, y = None): return self\n",
    "        def transform(self, X): return sparse.csr_matrix([[(len(x) - 360) / 550] for x in X])\n",
    "        def get_feature_names(self): return [\"lngth\"]\n",
    "\n",
    "    class LengthUpperTransformer(BaseEstimator, TransformerMixin):\n",
    "        def fit(self, X, y = None): return self\n",
    "        def transform(self, X): return sparse.csr_matrix([[sum([1 for y in x if y.isupper()]) / len(x)] for x in X])\n",
    "        def get_feature_names(self): return [\"lngth_uppercase\"]\n",
    "\n",
    "    df_val['upper_1'] = np.array(LengthUpperTransformer().transform(df_val['less_toxic']).todense()).reshape(-1, 1)\n",
    "    df_val['upper_2'] = np.array(LengthUpperTransformer().transform(df_val['more_toxic']).todense()).reshape(-1, 1)\n",
    "    df_val['upper_1'].hist(bins = 100)\n",
    "    df_val['upper_2'].hist(bins = 100)\n",
    "    val_preds_arr1 = np.zeros((df_val.shape[0], n_folds))\n",
    "    val_preds_arr2 = np.zeros((df_val.shape[0], n_folds))\n",
    "    test_preds_arr = np.zeros((df_sub.shape[0], n_folds))\n",
    "\n",
    "    for fld in range(n_folds):\n",
    "        df = pd.read_csv(f'/kaggle/working/df_fld{fld}.csv')\n",
    "        features = FeatureUnion([(\"vect3\", TfidfVectorizer(min_df = 3, max_df = 0.5, analyzer = 'char_wb', ngram_range = (3, 5)))])\n",
    "        pipeline = Pipeline([(\"features\", features), (\"clf\", Ridge())])\n",
    "        pipeline.fit(df['text'], df['y'])\n",
    "        feature_wts = sorted(list(zip(pipeline['features'].get_feature_names(), np.round(pipeline['clf'].coef_, 2))), key = lambda x: x[1], reverse = True)\n",
    "        pprint(feature_wts[:30])\n",
    "        val_preds_arr1[:, fld] = pipeline.predict(df_val['less_toxic'])\n",
    "        val_preds_arr2[:, fld] = pipeline.predict(df_val['more_toxic'])\n",
    "        test_preds_arr[:, fld] = pipeline.predict(df_sub['text'])\n",
    "\n",
    "    val_preds_arr1c = np.zeros((df_val.shape[0], n_folds))\n",
    "    val_preds_arr2c = np.zeros((df_val.shape[0], n_folds))\n",
    "    test_preds_arrc = np.zeros((df_sub.shape[0], n_folds))\n",
    "\n",
    "    for fld in range(n_folds):\n",
    "        df = pd.read_csv(f'/kaggle/working/df_clean_fld{fld}.csv')\n",
    "        features = FeatureUnion([(\"vect3\", TfidfVectorizer(min_df = 3, max_df = 0.5, analyzer = 'char_wb', ngram_range = (3, 5)))])\n",
    "        pipeline = Pipeline([(\"features\", features), (\"clf\", Ridge())])\n",
    "        pipeline.fit(df['text'], df['y'])\n",
    "        feature_wts = sorted(list(zip(pipeline['features'].get_feature_names(), np.round(pipeline['clf'].coef_, 2))), key = lambda x: x[1], reverse = True)\n",
    "        pprint(feature_wts[:30])\n",
    "        val_preds_arr1c[:, fld] = pipeline.predict(df_val['less_toxic'])\n",
    "        val_preds_arr2c[:, fld] = pipeline.predict(df_val['more_toxic'])\n",
    "        test_preds_arrc[:, fld] = pipeline.predict(df_sub['text'])\n",
    "\n",
    "    val_preds_arr1_ = np.zeros((df_val.shape[0], n_folds))\n",
    "    val_preds_arr2_ = np.zeros((df_val.shape[0], n_folds))\n",
    "    test_preds_arr_ = np.zeros((df_sub.shape[0], n_folds))\n",
    "    for fld in range(n_folds):\n",
    "        df = pd.read_csv(f'/kaggle/working/df2_fld{fld}.csv')\n",
    "        features = FeatureUnion([(\"vect3\", TfidfVectorizer(min_df = 3, max_df = 0.5, analyzer = 'char_wb', ngram_range = (3, 5)))])\n",
    "        pipeline = Pipeline([(\"features\", features), (\"clf\", Ridge())])\n",
    "        pipeline.fit(df['text'], df['y'])\n",
    "        feature_wts = sorted(list(zip(pipeline['features'].get_feature_names(), np.round(pipeline['clf'].coef_, 2))), key = lambda x: x[1], reverse = True)\n",
    "        pprint(feature_wts[:30])\n",
    "        val_preds_arr1_[:, fld] = pipeline.predict(df_val['less_toxic'])\n",
    "        val_preds_arr2_[:, fld] = pipeline.predict(df_val['more_toxic'])\n",
    "        test_preds_arr_[:, fld] = pipeline.predict(df_sub['text'])\n",
    "\n",
    "    del df, pipeline, feature_wts\n",
    "    gc.collect()\n",
    "\n",
    "    p5 = val_preds_arr1c.mean(axis = 1)\n",
    "    p6 = val_preds_arr2c.mean(axis = 1)\n",
    "    p5 = val_preds_arr1c.mean(axis = 1)\n",
    "    p6 = val_preds_arr2c.mean(axis = 1)\n",
    "    p1 = val_preds_arr1.mean(axis = 1)\n",
    "    p2 = val_preds_arr2.mean(axis = 1)\n",
    "    p3 = val_preds_arr1_.mean(axis = 1)\n",
    "    p4 = val_preds_arr2_.mean(axis = 1)\n",
    "    p5 = val_preds_arr1c.mean(axis = 1)\n",
    "    p6 = val_preds_arr2c.mean(axis = 1)\n",
    "\n",
    "    wts_acc = []\n",
    "    for i in range(30, 70, 1):\n",
    "        for j in range(0, 20, 1):\n",
    "            w1 = i / 100\n",
    "            w2 = (100 - i - j) / 100\n",
    "            w3 = (1 - w1 - w2)\n",
    "            p1_wt = w1 * p1 + w2 * p3 + w3 * p5\n",
    "            p2_wt = w1 * p2 + w2 * p4 + w3 * p6\n",
    "            wts_acc.append((w1, w2, w3, np.round((p1_wt < p2_wt).mean() * 100, 2)))\n",
    "    w1, w2, w3, _ = sorted(wts_acc, key = lambda x: x[2], reverse = True)[0]\n",
    "    p1_wt = w1 * p1 + w2 * p3 + w3 * p5\n",
    "    p2_wt = w1 * p2 + w2 * p4 + w3 * p6\n",
    "    df_val['p1'] = p1_wt\n",
    "    df_val['p2'] = p2_wt\n",
    "    df_val['diff'] = np.abs(p2_wt - p1_wt)\n",
    "    df_val['correct'] = (p1_wt < p2_wt).astype('int')\n",
    "    df_val[df_val.correct == 0].sort_values('diff', ascending = True).head(20)\n",
    "    df_val[df_val.correct == 0].sort_values('diff', ascending = False).head(20)\n",
    "    df_sub['score'] = w1 * test_preds_arr.mean(axis = 1) + w2 * test_preds_arr_.mean(axis = 1) + w3 * test_preds_arrc.mean(axis = 1)\n",
    "    df_sub['score'].count() - df_sub['score'].nunique()\n",
    "\n",
    "    same_score = df_sub['score'].value_counts().reset_index()[:10]\n",
    "    df_sub[df_sub['score'].isin(same_score['index'].tolist())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38033e43",
   "metadata": {
    "papermill": {
     "duration": 0.011096,
     "end_time": "2022-01-06T10:02:06.902391",
     "exception": false,
     "start_time": "2022-01-06T10:02:06.891295",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RoBERTa Ensemble 🔥\n",
    "_____\n",
    "#### **Credit:** Lake Arrowhead [[notebook](https://www.kaggle.com/vaby667/roberta-infere)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7b9229e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T10:02:07.076554Z",
     "iopub.status.busy": "2022-01-06T10:02:07.062064Z",
     "iopub.status.idle": "2022-01-06T10:02:07.124380Z",
     "shell.execute_reply": "2022-01-06T10:02:07.124984Z",
     "shell.execute_reply.started": "2022-01-01T17:00:15.100614Z"
    },
    "papermill": {
     "duration": 0.211853,
     "end_time": "2022-01-06T10:02:07.125225",
     "exception": false,
     "start_time": "2022-01-06T10:02:06.913372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if is_private():\n",
    "    import os\n",
    "    import gc\n",
    "    import cv2\n",
    "    import copy\n",
    "    import time\n",
    "    import random\n",
    "\n",
    "    # For data manipulation\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    # Pytorch Imports\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "    # For Transformer Models\n",
    "    from transformers import AutoTokenizer, AutoModel,AutoConfig\n",
    "\n",
    "    # Utils\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    # For descriptive error messages\n",
    "    os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "\n",
    "    class Config:\n",
    "\n",
    "        model_name = '../input/roberta-base'\n",
    "\n",
    "        learning_rate = 1e-4\n",
    "        epochs = 1\n",
    "        train_bs =32\n",
    "        valid_bs = 64\n",
    "        test_bs = 128\n",
    "\n",
    "        seed = 2021\n",
    "        max_length = 128\n",
    "        min_lr = 1e-7\n",
    "        scheduler = 'CosineAnnealingLR' # 学习率衰减策略\n",
    "        T_max  = 500\n",
    "        weight_decay = 1e-6 # 权重衰减 L2正则化 减少过拟合\n",
    "        max_grad_norm = 1.0 # 用于控制梯度膨胀，如果梯度向量的L2模超过max_grad_norm，则等比例缩小\n",
    "        num_classes = 1\n",
    "        margin = 0.5\n",
    "        n_fold = 5\n",
    "        n_accululate = 1\n",
    "        device= torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        hidden_size =768\n",
    "        num_hidden_layers = 24\n",
    "\n",
    "        dropout = 0.2\n",
    "\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(Config.model_name)\n",
    "\n",
    "    MODEL_PATHS = [\n",
    "        '../input/robertabase5fold2-linear-256/Loss-Fold-0.bin',\n",
    "        '../input/robertabase5fold2-linear-256/Loss-Fold-1.bin',\n",
    "        '../input/robertabase5fold2-linear-256/Loss-Fold-2.bin',\n",
    "        '../input/robertabase5fold2-linear-256/Loss-Fold-3.bin',\n",
    "        '../input/robertabase5fold2-linear-256/Loss-Fold-4.bin'\n",
    "    ]\n",
    "\n",
    "    def set_seed(seed = 42):\n",
    "        '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "        This is for REPRODUCIBILITY.'''\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        # When running on the CuDNN backend, two further options must be set\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        # Set a fixed value for the hash seed\n",
    "        os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "    set_seed(Config.seed)\n",
    "\n",
    "\n",
    "    df = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\n",
    "    df.head()\n",
    "\n",
    "\n",
    "    class JigsawDataset(Dataset):\n",
    "        def __init__(self, df, tokenizer, max_length):\n",
    "            self.df = df\n",
    "            self.max_len = max_length\n",
    "            self.tokenizer = tokenizer\n",
    "            self.text = df['text'].values\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.df)\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            text = self.text[index]\n",
    "            inputs = self.tokenizer.encode_plus(\n",
    "                            text,\n",
    "                            truncation=True,\n",
    "                            add_special_tokens=True,\n",
    "                            max_length=self.max_len,\n",
    "                            padding='max_length'\n",
    "                        )\n",
    "\n",
    "            ids = inputs['input_ids']\n",
    "            mask = inputs['attention_mask']        \n",
    "\n",
    "            return {\n",
    "                'ids': torch.tensor(ids, dtype=torch.long),\n",
    "                'mask': torch.tensor(mask, dtype=torch.long)\n",
    "            }\n",
    "\n",
    "\n",
    "    test_dataset = JigsawDataset(df, tokenizer, max_length=Config.max_length)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=Config.test_bs, num_workers=2, shuffle=False, pin_memory=True)\n",
    "\n",
    "    class JModel(nn.Module):\n",
    "        def __init__(self, checkpoint=Config.model_name, Config=Config):\n",
    "            super(JModel, self).__init__()\n",
    "            self.checkpoint = checkpoint\n",
    "            self.bert = AutoModel.from_pretrained(checkpoint, return_dict=False)\n",
    "            self.layer_norm = nn.LayerNorm(Config.hidden_size)\n",
    "            self.dropout = nn.Dropout(Config.dropout)\n",
    "            self.dense = nn.Sequential(\n",
    "                nn.Linear(Config.hidden_size, 256),\n",
    "                nn.LeakyReLU(negative_slope=0.01),\n",
    "                nn.Dropout(Config.dropout),\n",
    "                nn.Linear(256, 1)\n",
    "            )\n",
    "\n",
    "        def forward(self, input_ids, attention_mask):\n",
    "            _, pooled_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            pooled_output = self.layer_norm(pooled_output)\n",
    "            pooled_output = self.dropout(pooled_output)\n",
    "            preds = self.dense(pooled_output)\n",
    "            return preds        \n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def valid_fn(model, dataloader, device):\n",
    "        model.eval()\n",
    "\n",
    "        dataset_size = 0\n",
    "        running_loss = 0.0\n",
    "\n",
    "        PREDS = []\n",
    "\n",
    "        bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "        for step, data in bar:\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "\n",
    "            outputs = model(ids, mask)\n",
    "            PREDS.append(outputs.view(-1).cpu().detach().numpy()) \n",
    "\n",
    "        PREDS = np.concatenate(PREDS)\n",
    "        gc.collect()\n",
    "\n",
    "        return PREDS\n",
    "\n",
    "    def inference(model_paths, dataloader, device):\n",
    "        final_preds = []\n",
    "        for i, path in enumerate(model_paths):\n",
    "            model = JModel(Config.model_name)\n",
    "            model.to(Config.device)\n",
    "            model.load_state_dict(torch.load(path))\n",
    "\n",
    "            print(f\"Getting predictions for model {i+1}\")\n",
    "            preds = valid_fn(model, dataloader, device)\n",
    "            final_preds.append(preds)\n",
    "\n",
    "        final_preds = np.array(final_preds)\n",
    "        final_preds = np.mean(final_preds, axis=0)\n",
    "        return final_preds    \n",
    "\n",
    "    preds = inference(MODEL_PATHS, test_loader, Config.device)    \n",
    "    df['score'] = preds\n",
    "    df['score'] = df['score'].rank(method='first')\n",
    "    df.drop('text', axis=1, inplace=True)\n",
    "    df.to_csv(\"submission_bert.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77822eb5",
   "metadata": {
    "papermill": {
     "duration": 0.011171,
     "end_time": "2022-01-06T10:02:07.147593",
     "exception": false,
     "start_time": "2022-01-06T10:02:07.136422",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# RoBERTa Ensemble 2 🔥\n",
    "_____\n",
    "#### **Credit:** Old Monk [[notebook](https://www.kaggle.com/saurabhbagchi/0-824-jigsaw-inference)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23e53f09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T10:02:07.200433Z",
     "iopub.status.busy": "2022-01-06T10:02:07.194744Z",
     "iopub.status.idle": "2022-01-06T10:02:07.248411Z",
     "shell.execute_reply": "2022-01-06T10:02:07.247802Z"
    },
    "papermill": {
     "duration": 0.089583,
     "end_time": "2022-01-06T10:02:07.248572",
     "exception": false,
     "start_time": "2022-01-06T10:02:07.158989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if is_private():\n",
    "\n",
    "    import os\n",
    "    import gc\n",
    "    import cv2\n",
    "    import copy\n",
    "    import time\n",
    "    import random\n",
    "\n",
    "    # For data manipulation\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    # Pytorch Imports\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "    # For Transformer Models\n",
    "    from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "    # Utils\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    # For descriptive error messages\n",
    "    os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "    CONFIG = dict(\n",
    "        seed = 42,\n",
    "        model_name = '../input/roberta-base',\n",
    "        test_batch_size = 64,\n",
    "        max_length = 128,\n",
    "        num_classes = 1,\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    )\n",
    "\n",
    "    CONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])\n",
    "\n",
    "    MODEL_PATHS = [\n",
    "        '../input/pytorch-w-b-jigsaw-starter/Loss-Fold-0.bin',\n",
    "        '../input/pytorch-w-b-jigsaw-starter/Loss-Fold-1.bin',\n",
    "        '../input/pytorch-w-b-jigsaw-starter/Loss-Fold-2.bin',\n",
    "        '../input/pytorch-w-b-jigsaw-starter/Loss-Fold-3.bin',\n",
    "        '../input/pytorch-w-b-jigsaw-starter/Loss-Fold-4.bin'\n",
    "    ]\n",
    "\n",
    "    def set_seed(seed = 42):\n",
    "        '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "        This is for REPRODUCIBILITY.'''\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        # When running on the CuDNN backend, two further options must be set\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        # Set a fixed value for the hash seed\n",
    "        os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "\n",
    "    class JigsawDataset(Dataset):\n",
    "        def __init__(self, df, tokenizer, max_length):\n",
    "            self.df = df\n",
    "            self.max_len = max_length\n",
    "            self.tokenizer = tokenizer\n",
    "            self.text = df['text'].values\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.df)\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            text = self.text[index]\n",
    "            inputs = self.tokenizer.encode_plus(\n",
    "                            text,\n",
    "                            truncation=True,\n",
    "                            add_special_tokens=True,\n",
    "                            max_length=self.max_len,\n",
    "                            padding='max_length'\n",
    "                        )\n",
    "\n",
    "            ids = inputs['input_ids']\n",
    "            mask = inputs['attention_mask']        \n",
    "\n",
    "            return {\n",
    "                'ids': torch.tensor(ids, dtype=torch.long),\n",
    "                'mask': torch.tensor(mask, dtype=torch.long)\n",
    "            }    \n",
    "\n",
    "\n",
    "    class JigsawModel(nn.Module):\n",
    "        def __init__(self, model_name):\n",
    "            super(JigsawModel, self).__init__()\n",
    "            self.model = AutoModel.from_pretrained(model_name)\n",
    "            self.drop = nn.Dropout(p=0.2)\n",
    "            self.fc = nn.Linear(768, CONFIG['num_classes'])\n",
    "\n",
    "        def forward(self, ids, mask):        \n",
    "            out = self.model(input_ids=ids,attention_mask=mask,\n",
    "                             output_hidden_states=False)\n",
    "            out = self.drop(out[1])\n",
    "            outputs = self.fc(out)\n",
    "            return outputs\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def valid_fn(model, dataloader, device):\n",
    "        model.eval()\n",
    "\n",
    "        dataset_size = 0\n",
    "        running_loss = 0.0\n",
    "\n",
    "        PREDS = []\n",
    "\n",
    "        bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "        for step, data in bar:\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "\n",
    "            outputs = model(ids, mask)\n",
    "            PREDS.append(outputs.view(-1).cpu().detach().numpy()) \n",
    "\n",
    "        PREDS = np.concatenate(PREDS)\n",
    "        gc.collect()\n",
    "\n",
    "        return PREDS\n",
    "\n",
    "\n",
    "    def inference(model_paths, dataloader, device):\n",
    "        final_preds = []\n",
    "        for i, path in enumerate(model_paths):\n",
    "            model = JigsawModel(CONFIG['model_name'])\n",
    "            model.to(CONFIG['device'])\n",
    "            model.load_state_dict(torch.load(path))\n",
    "\n",
    "            print(f\"Getting predictions for model {i+1}\")\n",
    "            preds = valid_fn(model, dataloader, device)\n",
    "            final_preds.append(preds)\n",
    "\n",
    "        final_preds = np.array(final_preds)\n",
    "        final_preds = np.mean(final_preds, axis=0)\n",
    "        return final_preds\n",
    "\n",
    "\n",
    "    set_seed(CONFIG['seed'])\n",
    "    df = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\n",
    "    df.head()\n",
    "\n",
    "    test_dataset = JigsawDataset(df, CONFIG['tokenizer'], max_length=CONFIG['max_length'])\n",
    "    test_loader = DataLoader(test_dataset, batch_size=CONFIG['test_batch_size'],\n",
    "                             num_workers=2, shuffle=False, pin_memory=True)\n",
    "\n",
    "    preds1 = inference(MODEL_PATHS, test_loader, CONFIG['device'])\n",
    "    preds = pd.read_csv('submission_bert.csv')['score'].values\n",
    "    preds = (preds-preds.min())/(preds.max()-preds.min())\n",
    "    preds2 = (preds1-preds1.min())/(preds1.max()-preds1.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8140d70",
   "metadata": {
    "papermill": {
     "duration": 0.011392,
     "end_time": "2022-01-06T10:02:07.271402",
     "exception": false,
     "start_time": "2022-01-06T10:02:07.260010",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Ensembling with (TFIDF Ridge & FastText Ensemble) 🔥\n",
    "_____\n",
    "#### **Credit:** Ankit Gupta, Sahib Singh [[notebook](https://www.kaggle.com/nkitgupta/jigsaw-ridge-ensemble-tfidf-fasttext-0-868)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b89d59cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T10:02:07.321952Z",
     "iopub.status.busy": "2022-01-06T10:02:07.320539Z",
     "iopub.status.idle": "2022-01-06T10:02:07.369860Z",
     "shell.execute_reply": "2022-01-06T10:02:07.368919Z"
    },
    "papermill": {
     "duration": 0.08747,
     "end_time": "2022-01-06T10:02:07.370098",
     "exception": false,
     "start_time": "2022-01-06T10:02:07.282628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if is_private():\n",
    "    import re\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from scipy import sparse\n",
    "    from bs4 import BeautifulSoup\n",
    "    from sklearn.linear_model import Ridge\n",
    "    from gensim.models import KeyedVectors, FastText\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    import warnings; warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    N_MODELS = 4\n",
    "    EXTRA_DIM = 256\n",
    "    ALPHA_STEP_SIZE = 0.5\n",
    "\n",
    "\n",
    "    def text_cleaning(text):\n",
    "        template = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "        text = template.sub(r'', text)\n",
    "        soup = BeautifulSoup(text, 'lxml')\n",
    "        only_text = soup.get_text()\n",
    "        text = only_text\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "                                   u\"\\U0001F600-\\U0001F64F\"\n",
    "                                   u\"\\U0001F300-\\U0001F5FF\"\n",
    "                                   u\"\\U0001F680-\\U0001F6FF\"\n",
    "                                   u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "                                   u\"\\U00002702-\\U000027B0\"\n",
    "                                   u\"\\U000024C2-\\U0001F251\"\n",
    "                                   \"]+\", flags = re.UNICODE)\n",
    "        text = emoji_pattern.sub(r'', text)\n",
    "        text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text)\n",
    "        text = re.sub(' +', ' ', text)\n",
    "        text = text.strip()\n",
    "        return text\n",
    "\n",
    "    df = pd.read_csv('../input/jigsaw-regression-based-data/train_data.csv')\n",
    "    df = df.dropna(axis = 0)\n",
    "    vec = TfidfVectorizer(min_df = 3, max_df = 0.5, analyzer = 'char_wb', ngram_range = (3, 5), max_features = 46000)\n",
    "    vec.fit(df['text'])\n",
    "    fmodel = FastText.load('../input/jigsaw-regression-based-data/FastText-jigsaw-256D/Jigsaw-Fasttext-Word-Embeddings-256D.bin')\n",
    "\n",
    "    def splitter(text): return [word for word in text.split(' ')]\n",
    "    def vectorizer(text):\n",
    "        tokens = splitter(text)\n",
    "        x1 = vec.transform([text]).toarray()\n",
    "        x2 = np.mean(fmodel.wv[tokens], axis = 0).reshape(1, -1)\n",
    "        x = np.concatenate([x1, x2], axis = -1).astype(np.float16)\n",
    "        del x1\n",
    "        del x2\n",
    "        return x\n",
    "\n",
    "    X_np = np.array([vectorizer(text) for text in df.text]).reshape(-1, (len(vec.vocabulary_) + EXTRA_DIM))\n",
    "    X = sparse.csr_matrix(X_np)\n",
    "    del X_np\n",
    "\n",
    "    class RidgeEnsemble():\n",
    "        def __init__(self, n_models = 4, alpha_step_size = 0.5): self.models = [Ridge(alpha = alpha) for alpha in [alpha_step_size * i for i in range(1, n_models + 1)]]\n",
    "        def fit(self, X, y): self.models = [model.fit(X, y) for model in self.models]\n",
    "        def predict(self, X): return np.mean(np.concatenate([np.expand_dims(model.predict(X), axis = 0) for model in self.models], axis = 0), axis = 0)\n",
    "\n",
    "    model = RidgeEnsemble()\n",
    "    model.fit(X, df['y'])\n",
    "\n",
    "    df_val = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\n",
    "\n",
    "    X_less_toxic_temp = []\n",
    "    for text in df_val.less_toxic: X_less_toxic_temp.append(vectorizer(text))\n",
    "    X_less_toxic_temp = np.array(X_less_toxic_temp).reshape(-1, (len(vec.vocabulary_) + EXTRA_DIM))\n",
    "    X_less_toxic = sparse.csr_matrix(X_less_toxic_temp)\n",
    "    del X_less_toxic_temp\n",
    "\n",
    "    X_more_toxic_temp = []\n",
    "    for text in df_val.more_toxic: X_more_toxic_temp.append(vectorizer(text))\n",
    "    X_more_toxic_temp = np.array(X_more_toxic_temp).reshape(-1, (len(vec.vocabulary_) + EXTRA_DIM))\n",
    "    X_more_toxic = sparse.csr_matrix(X_more_toxic_temp)\n",
    "    del X_more_toxic_temp\n",
    "\n",
    "    df_sub2 = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\n",
    "    df_sub2['text'] = df_sub2['text'].apply(text_cleaning)\n",
    "    X_sub_temp = []\n",
    "    for text in df_sub2.text: X_sub_temp.append(vectorizer(text))\n",
    "    X_sub_temp = np.array(X_sub_temp).reshape(-1, (len(vec.vocabulary_) + 256))\n",
    "    X_test = sparse.csr_matrix(X_sub_temp)\n",
    "    del X_sub_temp\n",
    "\n",
    "    df_sub2['score'] = model.predict(X_test)\n",
    "    df_sub2['score'] = df_sub2['score']\n",
    "    df_sub2[['comment_id', 'score']].to_csv(\"submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cd70d62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T10:02:07.402186Z",
     "iopub.status.busy": "2022-01-06T10:02:07.400732Z",
     "iopub.status.idle": "2022-01-06T10:02:07.451297Z",
     "shell.execute_reply": "2022-01-06T10:02:07.450650Z",
     "shell.execute_reply.started": "2021-12-09T07:41:51.203124Z"
    },
    "papermill": {
     "duration": 0.069521,
     "end_time": "2022-01-06T10:02:07.451459",
     "exception": false,
     "start_time": "2022-01-06T10:02:07.381938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if is_private():        \n",
    "    df_sub['score'] = (0.4 * ((df_sub['score'] * 0.94) + (preds * 0.06))) + (0.6 * df_sub2['score'])\n",
    "    # df_sub['score'] = (1.0 * df_sub2['score'])\n",
    "    df_sub[['comment_id', 'score']].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "300f7e3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T10:02:07.480597Z",
     "iopub.status.busy": "2022-01-06T10:02:07.479828Z",
     "iopub.status.idle": "2022-01-06T10:02:07.711429Z",
     "shell.execute_reply": "2022-01-06T10:02:07.712363Z",
     "shell.execute_reply.started": "2021-12-09T07:41:51.216071Z"
    },
    "papermill": {
     "duration": 0.249727,
     "end_time": "2022-01-06T10:02:07.712560",
     "exception": false,
     "start_time": "2022-01-06T10:02:07.462833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not is_private():\n",
    "    df_sub = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\n",
    "    df_sub['score'] = 0.0\n",
    "    df_sub.to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12.843604,
   "end_time": "2022-01-06T10:02:08.438000",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-06T10:01:55.594396",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
